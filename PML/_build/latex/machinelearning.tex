%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{DejaVu Serif}
\setsansfont{DejaVu Sans}
\setmonofont{DejaVu Sans Mono}



\usepackage[Bjornstrup]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{0}


% Jupyter Notebook code cell colors
\definecolor{nbsphinxin}{HTML}{307FC1}
\definecolor{nbsphinxout}{HTML}{BF5B3D}
\definecolor{nbsphinx-code-bg}{HTML}{F5F5F5}
\definecolor{nbsphinx-code-border}{HTML}{E0E0E0}
\definecolor{nbsphinx-stderr}{HTML}{FFDDDD}
% ANSI colors for output streams and traceback highlighting
\definecolor{ansi-black}{HTML}{3E424D}
\definecolor{ansi-black-intense}{HTML}{282C36}
\definecolor{ansi-red}{HTML}{E75C58}
\definecolor{ansi-red-intense}{HTML}{B22B31}
\definecolor{ansi-green}{HTML}{00A250}
\definecolor{ansi-green-intense}{HTML}{007427}
\definecolor{ansi-yellow}{HTML}{DDB62B}
\definecolor{ansi-yellow-intense}{HTML}{B27D12}
\definecolor{ansi-blue}{HTML}{208FFB}
\definecolor{ansi-blue-intense}{HTML}{0065CA}
\definecolor{ansi-magenta}{HTML}{D160C4}
\definecolor{ansi-magenta-intense}{HTML}{A03196}
\definecolor{ansi-cyan}{HTML}{60C6C8}
\definecolor{ansi-cyan-intense}{HTML}{258F8F}
\definecolor{ansi-white}{HTML}{C5C1B4}
\definecolor{ansi-white-intense}{HTML}{A1A6B2}
\definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
\definecolor{ansi-default-inverse-bg}{HTML}{000000}

% Define an environment for non-plain-text code cell outputs (e.g. images)
\makeatletter
\newenvironment{nbsphinxfancyoutput}{%
    % Avoid fatal error with framed.sty if graphics too long to fit on one page
    \let\sphinxincludegraphics\nbsphinxincludegraphics
    \nbsphinx@image@maxheight\textheight
    \advance\nbsphinx@image@maxheight -2\fboxsep   % default \fboxsep 3pt
    \advance\nbsphinx@image@maxheight -2\fboxrule  % default \fboxrule 0.4pt
    \advance\nbsphinx@image@maxheight -\baselineskip
\def\nbsphinxfcolorbox{\spx@fcolorbox{nbsphinx-code-border}{white}}%
\def\FrameCommand{\nbsphinxfcolorbox\nbsphinxfancyaddprompt\@empty}%
\def\FirstFrameCommand{\nbsphinxfcolorbox\nbsphinxfancyaddprompt\sphinxVerbatim@Continues}%
\def\MidFrameCommand{\nbsphinxfcolorbox\sphinxVerbatim@Continued\sphinxVerbatim@Continues}%
\def\LastFrameCommand{\nbsphinxfcolorbox\sphinxVerbatim@Continued\@empty}%
\MakeFramed{\advance\hsize-\width\@totalleftmargin\z@\linewidth\hsize\@setminipage}%
\lineskip=1ex\lineskiplimit=1ex\raggedright%
}{\par\unskip\@minipagefalse\endMakeFramed}
\makeatother
\newbox\nbsphinxpromptbox
\def\nbsphinxfancyaddprompt{\ifvoid\nbsphinxpromptbox\else
    \kern\fboxrule\kern\fboxsep
    \copy\nbsphinxpromptbox
    \kern-\ht\nbsphinxpromptbox\kern-\dp\nbsphinxpromptbox
    \kern-\fboxsep\kern-\fboxrule\nointerlineskip
    \fi}
\newlength\nbsphinxcodecellspacing
\setlength{\nbsphinxcodecellspacing}{0pt}

% Define support macros for attaching opening and closing lines to notebooks
\newsavebox\nbsphinxbox
\makeatletter
\newcommand{\nbsphinxstartnotebook}[1]{%
    \par
    % measure needed space
    \setbox\nbsphinxbox\vtop{{#1\par}}
    % reserve some space at bottom of page, else start new page
    \needspace{\dimexpr2.5\baselineskip+\ht\nbsphinxbox+\dp\nbsphinxbox}
    % mimic vertical spacing from \section command
      \addpenalty\@secpenalty
      \@tempskipa 3.5ex \@plus 1ex \@minus .2ex\relax
      \addvspace\@tempskipa
      {\Large\@tempskipa\baselineskip
             \advance\@tempskipa-\prevdepth
             \advance\@tempskipa-\ht\nbsphinxbox
             \ifdim\@tempskipa>\z@
               \vskip \@tempskipa
             \fi}
    \unvbox\nbsphinxbox
    % if notebook starts with a \section, prevent it from adding extra space
    \@nobreaktrue\everypar{\@nobreakfalse\everypar{}}%
    % compensate the parskip which will get inserted by next paragraph
    \nobreak\vskip-\parskip
    % do not break here
    \nobreak
}% end of \nbsphinxstartnotebook

\newcommand{\nbsphinxstopnotebook}[1]{%
    \par
    % measure needed space
    \setbox\nbsphinxbox\vbox{{#1\par}}
    \nobreak % it updates page totals
    \dimen@\pagegoal
    \advance\dimen@-\pagetotal \advance\dimen@-\pagedepth
    \advance\dimen@-\ht\nbsphinxbox \advance\dimen@-\dp\nbsphinxbox
    \ifdim\dimen@<\z@
      % little space left
      \unvbox\nbsphinxbox
      \kern-.8\baselineskip
      \nobreak\vskip\z@\@plus1fil
      \penalty100
      \vskip\z@\@plus-1fil
      \kern.8\baselineskip
    \else
      \unvbox\nbsphinxbox
    \fi
}% end of \nbsphinxstopnotebook

% Ensure height of an included graphics fits in nbsphinxfancyoutput frame
\newdimen\nbsphinx@image@maxheight % set in nbsphinxfancyoutput environment
\newcommand*{\nbsphinxincludegraphics}[2][]{%
    \gdef\spx@includegraphics@options{#1}%
    \setbox\spx@image@box\hbox{\includegraphics[#1,draft]{#2}}%
    \in@false
    \ifdim \wd\spx@image@box>\linewidth
      \g@addto@macro\spx@includegraphics@options{,width=\linewidth}%
      \in@true
    \fi
    % no rotation, no need to worry about depth
    \ifdim \ht\spx@image@box>\nbsphinx@image@maxheight
      \g@addto@macro\spx@includegraphics@options{,height=\nbsphinx@image@maxheight}%
      \in@true
    \fi
    \ifin@
      \g@addto@macro\spx@includegraphics@options{,keepaspectratio}%
    \fi
    \setbox\spx@image@box\box\voidb@x % clear memory
    \expandafter\includegraphics\expandafter[\spx@includegraphics@options]{#2}%
}% end of "\MakeFrame"-safe variant of \sphinxincludegraphics
\makeatother

\makeatletter
\renewcommand*\sphinx@verbatim@nolig@list{\do\'\do\`}
\begingroup
\catcode`'=\active
\let\nbsphinx@noligs\@noligs
\g@addto@macro\nbsphinx@noligs{\let'\PYGZsq}
\endgroup
\makeatother
\renewcommand*\sphinxbreaksbeforeactivelist{\do\<\do\"\do\'}
\renewcommand*\sphinxbreaksafteractivelist{\do\.\do\,\do\:\do\;\do\?\do\!\do\/\do\>\do\-}
\makeatletter
\fvset{codes*=\sphinxbreaksattexescapedchars\do\^\^\let\@noligs\nbsphinx@noligs}
\makeatother


\usepackage[titles]{tocloft}
\cftsetpnumwidth {1.25cm}\cftsetrmarg{1.5cm}
\setlength{\cftchapnumwidth}{0.75cm}
\setlength{\cftsecindent}{\cftchapnumwidth}
\setlength{\cftsecnumwidth}{1.25cm}


\title{Machine Learning}
\date{Aug 22, 2022}
\release{01}
\author{Yavar T.\@{} Azar}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxstepscope


\chapter{Introduction}
\label{\detokenize{intro/intro:introduction}}\label{\detokenize{intro/intro::doc}}

\section{Types of ML}
\label{\detokenize{intro/intro:types-of-ml}}
\noindent\sphinxincludegraphics[width=700\sphinxpxdimen]{{MLtypes}.png}


\section{Supervised Learning}
\label{\detokenize{intro/intro:supervised-learning}}
\sphinxAtStartPar
Here, the term supervised refers to a set of samples where the desired output signals (labels) are
already known.

\sphinxAtStartPar
For example email with \sphinxtitleref{spam} or \sphinxtitleref{non\sphinxhyphen{}spam} labels and predicting the class of new email is a sample of \sphinxstylestrong{classification}

\sphinxAtStartPar
Another subcategory of supervised learning is \sphinxstylestrong{regression}, where the outcome signal is a continuous value

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{supervised}.png}

\sphinxAtStartPar
A sample two\sphinxhyphen{}dimensional data binary classification

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{twodim}.png}


\subsection{Regression (continuous outcomes)}
\label{\detokenize{intro/intro:regression-continuous-outcomes}}
\sphinxAtStartPar
In
regression analysis, we are given a number of \sphinxstylestrong{predictor (explanatory)} variables and a continuous \sphinxstylestrong{response variable (outcome)}, and we try to find a relationship between those variables that allows us to predict an outcome.

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{regression}.png}


\section{Reinforcement learning}
\label{\detokenize{intro/intro:reinforcement-learning}}

\section{Unsupervised learning}
\label{\detokenize{intro/intro:unsupervised-learning}}
\sphinxAtStartPar
Simple 2D clustering example based on the similarity of their features x1 and x2

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{cluster}.png}


\section{Dimensionality reduction}
\label{\detokenize{intro/intro:dimensionality-reduction}}
\sphinxAtStartPar
\(x^{(i)}_j\) we will use the superscript \sphinxstylestrong{(i)} to refer to the ith training sample, and the subscript \sphinxstylestrong{j} to refer to the jth dimension of the training dataset.


\section{ML Roadmap}
\label{\detokenize{intro/intro:ml-roadmap}}
\sphinxAtStartPar
Here

\noindent\sphinxincludegraphics[width=700\sphinxpxdimen]{{roadmap}.png}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Preprocessing – getting data into shape

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{preprocessing}  ;  transforming the features in the range {[}0,1{]} or normal distribution

\sphinxAtStartPar
for coorelated and redundant data –>  dimensionality reduction techniques
\begin{itemize}
\item {} 
\sphinxAtStartPar
Training and selecting a predictive model

\end{itemize}

\sphinxAtStartPar
One legitimate question to ask is: how do we know which model performs well on the final test data\sphinxhyphen{}set and real\sphinxhyphen{}world data if we don’t use this test set for the model selection but keep it for the final model evaluation?

\sphinxAtStartPar
inally, we also cannot expect that the default parameters of the different learning algorithms provided by software libraries are
optimal for our specific problem task.  hyperparameter optimization techniques
\begin{itemize}
\item {} 
\sphinxAtStartPar
Evaluating models and predicting unseen data instances

\end{itemize}

\sphinxstepscope


\chapter{Perceptron}
\label{\detokenize{percept/percept:perceptron}}\label{\detokenize{percept/percept::doc}}
\sphinxstepscope


\section{Basic cocepts}
\label{\detokenize{percept/basics:basic-cocepts}}\label{\detokenize{percept/basics::doc}}
\sphinxAtStartPar
The Perceptron is a linear machine learning algorithm for binary classification tasks.

\sphinxAtStartPar
It may be considered one of the first and one of the simplest types of artificial neural networks. It is definitely not “deep” learning but is an important building block.

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{biological-neuron}.jpg}


\subsection{Perceptron Algorithm}
\label{\detokenize{percept/basics:perceptron-algorithm}}
\sphinxAtStartPar
The Perceptron algorithm is a two\sphinxhyphen{}class (binary) classification machine learning algorithm.

\sphinxAtStartPar
It is a type of neural network model, perhaps the simplest type of neural network model.

\sphinxAtStartPar
It consists of a single node or neuron that takes a row of data as input and predicts a class label.
This is achieved by calculating the weighted sum of the inputs and a bias (set to 1).
The weighted sum of the input of the model is called the activation.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Activation = Weights * Inputs + Bias

\end{itemize}

\sphinxAtStartPar
If the activation is above \sphinxstylestrong{threshold}, the model will output 1.0; otherwise, it will output 0.0.

\sphinxAtStartPar
The Perceptron is a linear classification algorithm. This means that it learns a decision boundary that separates two classes using a line (called a \sphinxstylestrong{hyperplane})
in the feature space. As such, it is appropriate for those problems where the classes can be separated well by a line or linear model,
referred to as linearly separable.

\sphinxAtStartPar
Examples from the training dataset are shown to the model one at a time, the model makes a prediction, and error is calculated. The weights of the model are then updated to reduce the errors for the example. This is called the Perceptron update rule. This process is repeated for all examples in the training dataset, called an epoch. This process of updating the model using examples is then repeated for many epochs.

\sphinxAtStartPar
Model weights are updated with a small proportion of the error each batch, and the proportion is controlled by a hyperparameter called the learning rate, typically set to a small value. This is to ensure learning does not occur too quickly, resulting in a possibly lower skill model, referred to as premature convergence of the optimization (search) procedure for the model weights.

\sphinxAtStartPar
\sphinxtitleref{weights(t + 1) = weights(t) + learning\_rate * (expected\_i – predicted\_) * input\_i}
Training is stopped when the error made by the model falls to a low level or no longer improves, or a maximum number of epochs is performed.

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{Perceptron_alg}.jpg}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
The learning rate and number of training epochs are hyperparameters of the algorithm that can be set using heuristics or hyperparameter tuning.
\end{sphinxadmonition}


\subsubsection{Hands\sphinxhyphen{}on}
\label{\detokenize{percept/basics:hands-on}}
\sphinxAtStartPar
How to Implement the Perceptron Algorithm From Scratch in Python

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/env python3}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{}*\PYGZhy{} coding: utf\PYGZhy{}8 \PYGZhy{}*\PYGZhy{}}
\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{Created on Sat Aug 20 14:52:27 2022}

\PYG{l+s+sd}{@author: yavar}
\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{k}{class} \PYG{n+nc}{Perceptron}\PYG{p}{(}\PYG{n+nb}{object}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Perceptron classifier.}
\PYG{l+s+sd}{    Parameters}
\PYG{l+s+sd}{    \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{l+s+sd}{    eta : float}
\PYG{l+s+sd}{    Learning rate (between 0.0 and 1.0)}
\PYG{l+s+sd}{    n\PYGZus{}iter : int}
\PYG{l+s+sd}{    Passes over the training dataset.}
\PYG{l+s+sd}{    Attributes}
\PYG{l+s+sd}{    \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{l+s+sd}{    w\PYGZus{} : 1d\PYGZhy{}array}
\PYG{l+s+sd}{    Weights after fitting.}
\PYG{l+s+sd}{    errors\PYGZus{} : list}
\PYG{l+s+sd}{    Number of misclassifications in every epoch.}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{eta}\PYG{o}{=}\PYG{l+m+mf}{0.01}\PYG{p}{,} \PYG{n}{n\PYGZus{}iter}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{eta} \PYG{o}{=} \PYG{n}{eta}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{n\PYGZus{}iter} \PYG{o}{=} \PYG{n}{n\PYGZus{}iter}

    \PYG{k}{def} \PYG{n+nf}{fit}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}\PYG{p}{:}


        \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Fit training data.}
\PYG{l+s+sd}{        Parameters}
\PYG{l+s+sd}{        \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{l+s+sd}{        X : \PYGZob{}array\PYGZhy{}like\PYGZcb{}, shape = [n\PYGZus{}samples, n\PYGZus{}features]}
\PYG{l+s+sd}{        Training vectors, where n\PYGZus{}samples}
\PYG{l+s+sd}{        is the number of samples and}
\PYG{l+s+sd}{        n\PYGZus{}features is the number of features.}
\PYG{l+s+sd}{        y : array\PYGZhy{}like, shape = [n\PYGZus{}samples]}
\PYG{l+s+sd}{        Target values.}
\PYG{l+s+sd}{        Returns}
\PYG{l+s+sd}{        \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{l+s+sd}{        self : object}
\PYG{l+s+sd}{        \PYGZdq{}\PYGZdq{}\PYGZdq{}}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{w\PYGZus{}} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{+} \PYG{n}{X}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{errors\PYGZus{}} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
        \PYG{k}{for} \PYG{n}{\PYGZus{}} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{n\PYGZus{}iter}\PYG{p}{)}\PYG{p}{:}
            \PYG{n}{errors} \PYG{o}{=} \PYG{l+m+mi}{0}
            \PYG{k}{for} \PYG{n}{xi}\PYG{p}{,} \PYG{n}{target} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}\PYG{p}{:}
                \PYG{n}{update} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{eta} \PYG{o}{*} \PYG{p}{(}\PYG{n}{target} \PYG{o}{\PYGZhy{}} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{xi}\PYG{p}{)}\PYG{p}{)}
                \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{w\PYGZus{}}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{:}\PYG{p}{]} \PYG{o}{+}\PYG{o}{=} \PYG{n}{update} \PYG{o}{*} \PYG{n}{xi}
                \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{w\PYGZus{}}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{+}\PYG{o}{=} \PYG{n}{update}
                \PYG{n}{errors} \PYG{o}{+}\PYG{o}{=} \PYG{n+nb}{int}\PYG{p}{(}\PYG{n}{update} \PYG{o}{!=} \PYG{l+m+mf}{0.0}\PYG{p}{)}
            \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{errors\PYGZus{}}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{errors}\PYG{p}{)}
        \PYG{k}{return} \PYG{n+nb+bp}{self}

    \PYG{k}{def} \PYG{n+nf}{net\PYGZus{}input}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{X}\PYG{p}{)}\PYG{p}{:}
        \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Calculate net input\PYGZdq{}\PYGZdq{}\PYGZdq{}}
        \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{dot}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{w\PYGZus{}}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{:}\PYG{p}{]}\PYG{p}{)} \PYG{o}{+} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{w\PYGZus{}}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
    \PYG{k}{def} \PYG{n+nf}{predict}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{X}\PYG{p}{)}\PYG{p}{:}
        \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Return class label after unit step\PYGZdq{}\PYGZdq{}\PYGZdq{}}
        \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{net\PYGZus{}input}\PYG{p}{(}\PYG{n}{X}\PYG{p}{)} \PYG{o}{\PYGZgt{}}\PYG{o}{=} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
After creation of above class we can use it

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+ch}{\PYGZsh{}!/usr/bin/env python3}
\PYG{c+c1}{\PYGZsh{} \PYGZhy{}*\PYGZhy{} coding: utf\PYGZhy{}8 \PYGZhy{}*\PYGZhy{}}
\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{Created on Sat Aug 20 14:52:27 2022}

\PYG{l+s+sd}{@author: yavar}
\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}

\PYG{k+kn}{from} \PYG{n+nn}{percept} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}


\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}


\PYG{n}{df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{iris.data}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}


\PYG{n}{y} \PYG{o}{=} \PYG{n}{df}\PYG{o}{.}\PYG{n}{iloc}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{100}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}\PYG{o}{.}\PYG{n}{values}

\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{y} \PYG{o}{==} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Iris\PYGZhy{}setosa}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}


\PYG{n}{X} \PYG{o}{=} \PYG{n}{df}\PYG{o}{.}\PYG{n}{iloc}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{100}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{]}\PYG{o}{.}\PYG{n}{values}



\PYG{c+c1}{\PYGZsh{} plt.scatter(X[:50, 0], X[:50, 1], color=\PYGZsq{}red\PYGZsq{}, marker=\PYGZsq{}o\PYGZsq{}, label=\PYGZsq{}setosa\PYGZsq{})}

\PYG{c+c1}{\PYGZsh{} plt.scatter(X[50:100, 0], X[50:100, 1],color=\PYGZsq{}blue\PYGZsq{}, marker=\PYGZsq{}x\PYGZsq{}, label=\PYGZsq{}versicolor\PYGZsq{})}
\PYG{c+c1}{\PYGZsh{} plt.xlabel(\PYGZsq{}petal length\PYGZsq{})}
\PYG{c+c1}{\PYGZsh{} plt.ylabel(\PYGZsq{}sepal length\PYGZsq{})}
\PYG{c+c1}{\PYGZsh{} plt.legend(loc=\PYGZsq{}upper left\PYGZsq{})}
\PYG{c+c1}{\PYGZsh{}plt.show()}


\PYG{n}{ppn} \PYG{o}{=} \PYG{n}{Perceptron}\PYG{p}{(}\PYG{n}{eta}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{n}{n\PYGZus{}iter}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{)}


\PYG{n}{jj}\PYG{o}{=}\PYG{n}{ppn}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{ppn}\PYG{o}{.}\PYG{n}{errors\PYGZus{}}\PYG{p}{)} \PYG{o}{+} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{ppn}\PYG{o}{.}\PYG{n}{errors\PYGZus{}}\PYG{p}{,}\PYG{n}{marker}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{o}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Epochs}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Number of misclassifications}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
here is coode run result

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{pract1}.png}

\sphinxstepscope


\section{Scikit\sphinxhyphen{}learn perceptron}
\label{\detokenize{percept/scikit/scikit/scikit:scikit-learn-perceptron}}\label{\detokenize{percept/scikit/scikit/scikit::doc}}
\sphinxAtStartPar
Here we will try perceptron inside scikit\sphinxhyphen{}learn library

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}

\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k+kn}{import} \PYG{n}{colors}
\PYG{n}{ll} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}112031}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}152D35}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}345B63}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsh{}D4ECDD}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
\PYG{n}{ll}\PYG{o}{.}\PYG{n}{reverse}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{cmap} \PYG{o}{=} \PYG{n}{colors}\PYG{o}{.}\PYG{n}{ListedColormap}\PYG{p}{(}\PYG{n}{ll}\PYG{p}{)}

\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{load\PYGZus{}digits}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{Perceptron}
\PYG{n}{X}\PYG{p}{,} \PYG{n}{y} \PYG{o}{=} \PYG{n}{load\PYGZus{}digits}\PYG{p}{(}\PYG{n}{return\PYGZus{}X\PYGZus{}y}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}what is random stat?}
\PYG{n}{clf} \PYG{o}{=} \PYG{n}{Perceptron}\PYG{p}{(}\PYG{n}{tol}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}1}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,} \PYG{n}{l1\PYGZus{}ratio}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}



\sphinxAtStartPar
let’s take a look to the first 18 data inside X dataset

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{test} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{zeros}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{18}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{18}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{test}\PYG{p}{[}\PYG{n}{i}\PYG{p}{,}\PYG{p}{:}\PYG{p}{,}\PYG{p}{:}\PYG{p}{]}\PYG{o}{=}\PYG{n}{np}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{n}{X}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,}\PYG{p}{(}\PYG{l+m+mi}{8}\PYG{p}{,} \PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{15}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{axs} \PYG{o}{=} \PYG{n}{axs}\PYG{o}{.}\PYG{n}{ravel}\PYG{p}{(}\PYG{p}{)}


\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{18}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{axs}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{test}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{n}{cmap}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics[width=841\sphinxpxdimen,height=357\sphinxpxdimen]{{output_4_0}.png}

\sphinxAtStartPar
lets see what predicted by our perceptron

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{results}\PYG{o}{=} \PYG{n}{clf}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{X}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{   prediction |  real value  |  difference}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{18}\PYG{p}{)}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}:10d\PYGZcb{}}\PYG{l+s+s2}{    | }\PYG{l+s+si}{\PYGZob{}:10d\PYGZcb{}}\PYG{l+s+s2}{   |  }\PYG{l+s+si}{\PYGZob{}:10d\PYGZcb{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{results}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{y}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{results}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{\PYGZhy{}}\PYG{n}{y}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
   \PYG{n}{prediction} \PYG{o}{|}  \PYG{n}{real} \PYG{n}{value}  \PYG{o}{|}  \PYG{n}{difference}
\PYG{n}{\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}\PYGZus{}}

         \PYG{l+m+mi}{0}    \PYG{o}{|}          \PYG{l+m+mi}{0}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{1}    \PYG{o}{|}          \PYG{l+m+mi}{1}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{2}    \PYG{o}{|}          \PYG{l+m+mi}{2}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{3}    \PYG{o}{|}          \PYG{l+m+mi}{3}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{4}    \PYG{o}{|}          \PYG{l+m+mi}{4}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{9}    \PYG{o}{|}          \PYG{l+m+mi}{5}   \PYG{o}{|}           \PYG{l+m+mi}{4}
         \PYG{l+m+mi}{6}    \PYG{o}{|}          \PYG{l+m+mi}{6}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{7}    \PYG{o}{|}          \PYG{l+m+mi}{7}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{8}    \PYG{o}{|}          \PYG{l+m+mi}{8}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{9}    \PYG{o}{|}          \PYG{l+m+mi}{9}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{0}    \PYG{o}{|}          \PYG{l+m+mi}{0}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{1}    \PYG{o}{|}          \PYG{l+m+mi}{1}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{2}    \PYG{o}{|}          \PYG{l+m+mi}{2}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{3}    \PYG{o}{|}          \PYG{l+m+mi}{3}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{4}    \PYG{o}{|}          \PYG{l+m+mi}{4}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{5}    \PYG{o}{|}          \PYG{l+m+mi}{5}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{6}    \PYG{o}{|}          \PYG{l+m+mi}{6}   \PYG{o}{|}           \PYG{l+m+mi}{0}
         \PYG{l+m+mi}{7}    \PYG{o}{|}          \PYG{l+m+mi}{7}   \PYG{o}{|}           \PYG{l+m+mi}{0}
\end{sphinxVerbatim}

\sphinxAtStartPar
lets see how many results are accurate

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{diff} \PYG{o}{=} \PYG{n}{results}\PYG{o}{\PYGZhy{}}\PYG{n}{y}

\PYG{n}{nonzeros} \PYG{o}{=} \PYG{n}{diff}\PYG{p}{[}\PYG{n}{diff}\PYG{o}{!=}\PYG{l+m+mi}{0}\PYG{p}{]}

\PYG{n}{nzlen}\PYG{o}{=}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{nonzeros}\PYG{p}{)}
\PYG{n}{alldata}\PYG{o}{=}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{y}\PYG{p}{)}


\PYG{n}{accuracy} \PYG{o}{=} \PYG{p}{(}\PYG{n}{alldata}\PYG{o}{\PYGZhy{}}\PYG{n}{nzlen}\PYG{p}{)}\PYG{o}{/}\PYG{n}{alldata}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{accuracy}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mf}{0.9710628825820813}
\end{sphinxVerbatim}

\sphinxAtStartPar
Check output of perceprton score method

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{score}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,}\PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mf}{0.9710628825820813}
\end{sphinxVerbatim}

\sphinxAtStartPar
Our estiamtion is very good !

\sphinxstepscope


\chapter{Classification}
\label{\detokenize{classification/classification:classification}}\label{\detokenize{classification/classification::doc}}
\sphinxstepscope


\chapter{Regression Analysis in ML}
\label{\detokenize{regression/regression:regression-analysis-in-ml}}\label{\detokenize{regression/regression::doc}}
\sphinxAtStartPar
Regression analysis is a statistical method to model the relationship between a dependent (target)
and independent (predictor) variables with one or more independent variables. More specifically,
Regression analysis helps us to understand how the value of the dependent variable is changing
corresponding to an independent variable when other independent variables are held fixed.
It predicts continuous/real values such as temperature, age, salary, price, etc.

\sphinxAtStartPar
In Regression, we plot a graph between the variables which best fits the given datapoints, using this plot, the machine learning model can make predictions about the data. In simple words, “Regression shows a line or curve that passes through all the datapoints on target\sphinxhyphen{}predictor graph in such a way that the vertical distance between the datapoints and the regression line is minimum.” The distance between datapoints and line tells whether a model has captured a strong relationship or not.

\sphinxAtStartPar
Some examples of regression can be as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Prediction of rain using temperature and other factors

\item {} 
\sphinxAtStartPar
Determining Market trends

\item {} 
\sphinxAtStartPar
Prediction of road accidents due to rash driving.

\end{itemize}


\section{Basic terminology}
\label{\detokenize{regression/regression:basic-terminology}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Dependent Variable: The main factor in Regression analysis which we want to predict or understand is called the dependent variable. It is also called target variable.

\item {} 
\sphinxAtStartPar
Independent Variable: The factors which affect the dependent variables or which are used to predict the values of the dependent variables are called independent variable, also called as a predictor.

\item {} 
\sphinxAtStartPar
Outliers: Outlier is an observation which contains either very low value or very high value in comparison to other observed values. An outlier may hamper the result, so it should be avoided.

\item {} 
\sphinxAtStartPar
Multicollinearity: If the independent variables are highly correlated with each other than other variables, then such condition is called Multicollinearity. It should not be present in the dataset, because it creates problem while ranking the most affecting variable.

\item {} 
\sphinxAtStartPar
Underfitting and Overfitting: If our algorithm works well with the training dataset but not well with test dataset, then such problem is called Overfitting. And if our algorithm does not perform well even with training dataset, then such problem is called underfitting.

\end{itemize}


\section{Types of regression}
\label{\detokenize{regression/regression:types-of-regression}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=350\sphinxpxdimen]{{types-of-regression}.png}}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Linear Regression

\item {} 
\sphinxAtStartPar
Logistic Regression

\item {} 
\sphinxAtStartPar
Polynomial Regression

\item {} 
\sphinxAtStartPar
Support Vector Regression

\item {} 
\sphinxAtStartPar
Decision Tree Regression

\item {} 
\sphinxAtStartPar
Random Forest Regression

\item {} 
\sphinxAtStartPar
Ridge Regression

\item {} 
\sphinxAtStartPar
Lasso Regression:

\end{itemize}

\sphinxAtStartPar
Each method can be used for different scenario


\subsection{Linear regression}
\label{\detokenize{regression/regression:linear-regression}}
\sphinxAtStartPar
Linear regression shows the linear relationship between the independent variable (X\sphinxhyphen{}axis) and the dependent variable (Y\sphinxhyphen{}axis), hence called linear regression.

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{linearreg}.png}

\sphinxAtStartPar
a mathematical euqation for regression can bes shown
\begin{equation*}
\begin{split}Y= aX+b\end{split}
\end{equation*}
\begin{DUlineblock}{0em}
\item[] Here, Y = dependent variables (target variables),
\item[] X= Independent variables (predictor variables),
\item[] a and b are the linear coefficients
\end{DUlineblock}


\subsection{Polynomial Regression}
\label{\detokenize{regression/regression:polynomial-regression}}
\sphinxAtStartPar
Polynomial Regression is a type of regression which models the non\sphinxhyphen{}linear dataset using a linear model.
It is similar to multiple linear regression, but it fits a non\sphinxhyphen{}linear curve between the value of x and corresponding conditional values of y.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
In Polynomial regression, the original features are transformed into polynomial features of given degree and then modeled using a linear model. Which means the datapoints are best fitted using a polynomial line.
\end{sphinxadmonition}

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{polynomial}.png}


\subsection{Logistic Regression}
\label{\detokenize{regression/regression:logistic-regression}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Logistic regression is another supervised learning algorithm which is used to solve the classification problems. In classification problems, we have dependent variables in a binary or discrete format such as 0 or 1.

\item {} 
\sphinxAtStartPar
Logistic regression algorithm works with the categorical variable such as 0 or 1, Yes or No, True or False, Spam or not spam, etc.

\item {} 
\sphinxAtStartPar
Logistic regression uses sigmoid function or logistic function which is a complex cost function. This sigmoid function is used to model the data in logistic regression. The function can be represented as
\begin{equation*}
\begin{split}f(x)=\frac{1}{1+e^{-x}}\end{split}
\end{equation*}
\end{itemize}

\sphinxAtStartPar
where, f(x)= Output between the 0 and 1 value and x= input to the function


\subsection{Support Vector Regression}
\label{\detokenize{regression/regression:support-vector-regression}}

\subsection{Decision Tree Regression}
\label{\detokenize{regression/regression:decision-tree-regression}}
\sphinxAtStartPar
Decision Tree is a supervised learning algorithm which can be used for solving both classification and regression problems.

\noindent\sphinxincludegraphics[width=400\sphinxpxdimen]{{decissiontree}.png}

\sphinxstepscope


\chapter{Data Preprocessing}
\label{\detokenize{datapre/datapre:data-preprocessing}}\label{\detokenize{datapre/datapre::doc}}
\sphinxstepscope


\chapter{Neural Network}
\label{\detokenize{nn/nn:neural-network}}\label{\detokenize{nn/nn::doc}}

\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{search}

\end{itemize}



\renewcommand{\indexname}{Index}
\footnotesize\raggedright\printindex
\end{document}